{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "190a0f13-2b6b-4f9e-b382-b76c247a7cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import transformers\n",
    "import timm\n",
    "\n",
    "from transformers import ViTFeatureExtractor, ViTModel\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbbd7d8-fc17-46c9-9f66-36b51dc38e84",
   "metadata": {},
   "source": [
    "# Image models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfe721fa-228d-41c2-a031-525043abcd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize((256, 256)),\n",
    "        torchvision.transforms.CenterCrop((224, 224)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f79ba99e-8544-4e44-9b4b-67bd874864aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"/data3/dataset/0a/01/0a01028bdb7383ba409036cdad89e0cc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0d9d96e-f682-4e2a-9b2d-0670425d99be",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Носок розовый\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "028698e1-1872-4f48-b04b-181379106cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms(image).unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10d36ea-4431-447a-967c-45d243d7c6cf",
   "metadata": {},
   "source": [
    "### DINO v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3b14879-54ef-42eb-a252-3772b889f2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/aruslantsev/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "xFormers not available\n",
      "xFormers not available\n"
     ]
    }
   ],
   "source": [
    "dino = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39878e2b-7116-4b6c-8274-319de166d56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dino(transforms(image).unsqueeze(0)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af370d02-b0aa-43dd-8347-1402fd84e127",
   "metadata": {},
   "source": [
    "### ViT PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3166a2b1-d859-4967-a3a1-6cd4b2d52767",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit = torchvision.models.vit_l_32(weights=torchvision.models.ViT_L_32_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2147957-db61-4f3c-a158-a5d9bab5ce76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit(transforms(image).unsqueeze(0)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4403f1-ee40-4861-85d6-d97099df866a",
   "metadata": {},
   "source": [
    "### ViT TIMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2b50efb-a7da-4ba1-8c83-b51dab5d041e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.models.vision_transformer.vit_base_patch16_224_dino()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ede9126-c9e9-4dac-a0b3-40745be557a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(transforms(image).unsqueeze(0)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e67237-2eab-43e4-9ac2-252f62639fbf",
   "metadata": {},
   "source": [
    "### ViT Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ec2949-85e0-4194-8fb8-3037420df71b",
   "metadata": {},
   "source": [
    "Returns tokens' vectors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d986005a-196e-477c-ba0d-c562949983f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aruslantsev/miniconda3/envs/common/lib/python3.8/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at facebook/dino-vitb16 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = ViTFeatureExtractor.from_pretrained('facebook/dino-vitb16')\n",
    "model = ViTModel.from_pretrained('facebook/dino-vitb16')\n",
    "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef29b255-fed8-4691-986f-334054bb0217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 197, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25bbbe74-3cc2-4b47-bfe9-1801a9f00cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.pooler_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791d1450-2822-447e-b3ce-ea1961d4581c",
   "metadata": {},
   "source": [
    "# Text models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d59240-4f1f-4fb7-aac9-3d6bd85d6fba",
   "metadata": {},
   "source": [
    "### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38524409-9ceb-4f7b-8485-deb7cfa220a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c059d50-ca24-4133-accd-62ed52c8c0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(title, return_tensors=\"pt\")\n",
    "outputs = bert(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a63e9707-2a5a-4bad-aeee-24927cdabd64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 13, 768])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8e4efb-ecd3-4e37-a251-0cc851210b34",
   "metadata": {},
   "source": [
    "# Combine text and image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b5a679b-8221-4f4a-8243-4640fcc41449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using cache found in /home/aruslantsev/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "dino = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14')\n",
    "\n",
    "bert_multi = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f057140e-2a47-4d03-8336-8c3648a5a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(title, return_tensors=\"pt\")\n",
    "text_inp = bert(**inputs).last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65c46896-9f4e-4223-af02-935a3d45cd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_inp = dino(transforms(image).unsqueeze(0)).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a38cd2-8bab-4a8f-955f-89f80de90ba9",
   "metadata": {},
   "source": [
    "Vector norms are different. Maybe need to scale?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbf19f40-df59-4023-8c90-52378b918861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(46.9338, grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_inp.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43e16946-e670-4d63-8a8f-918cb8116ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.1290, grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_inp[0, 0, :].norm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ed42c3-6d90-40d6-a858-f80019fca9b0",
   "metadata": {},
   "source": [
    "### Custom tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a03231f-db8f-42c0-baf8-916c1d59746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLS = torch.zeros(1, 1, 768)\n",
    "CLS[0, 0, 0] = 1\n",
    "\n",
    "SEP = torch.zeros(1, 1, 768)\n",
    "SEP[0, 0, 1] = 1\n",
    "\n",
    "SEP_IMG = torch.zeros(1, 1, 768)\n",
    "SEP_IMG[0, 0, 2] = 1\n",
    "\n",
    "SEP_SKU_IMG = torch.zeros(1, 1, 768)\n",
    "SEP_SKU_IMG[0, 0, 2] = 1\n",
    "\n",
    "PAD = torch.zeros(1, 1, 768)\n",
    "PAD[0, 0, -1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9bb75f5-9483-48c0-b48e-224d4e14bd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_inp = torch.hstack(\n",
    "    [\n",
    "        CLS, \n",
    "        text_inp / text_inp.norm(keepdim=True, dim=2), \n",
    "        SEP_IMG, \n",
    "        image_inp / image_inp.norm(keepdim=True, dim=2), \n",
    "        SEP\n",
    "    ] + [\n",
    "        PAD\n",
    "    ] * (64 - 17)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d46c8df5-2672-4ead-a6bc-5079e37d45cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 768])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "647d95ee-c19d-4c03-af16-ee7336b3bb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_multi(inputs_embeds=vec_inp).pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48be9d02-a03c-4986-92e0-a7cc0162197f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sd_prompts37",
   "language": "python",
   "name": "sd_prompts37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
